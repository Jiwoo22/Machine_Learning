{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43534tdfgs-v"
   },
   "source": [
    "``Objectives``\n",
    "\n",
    "* training feed-forward fully connected neural networks (FFNN);\n",
    "\n",
    "* a full set of experiments to explore different hyperparameters and hidden layer sizes for two datasets, and then document your findings.\n",
    "\n",
    "``Data``\n",
    "* Digits MNIST\n",
    "* Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZE4QpA5SpDH"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiwoochoi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL5O-SOu7kYN"
   },
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUw6VVIsSpDJ",
    "outputId": "600be355-302e-40e1-ce56-57ebf5cfe4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m 5513216/11490434\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 3us/step"
     ]
    }
   ],
   "source": [
    "# Load the Fashion MNIST dataset.\n",
    "(X_train_fashion, Y_train_fashion), (X_test_fashion, Y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Load the Digits MNIST dataset.\n",
    "(X_train_digits, Y_train_digits), (X_test_digits, Y_test_digits) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em38-uUQSpDK"
   },
   "source": [
    "---\n",
    "### Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRKm16HySpDK"
   },
   "source": [
    "``Fashion MNIST``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_auto_data_set_code"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train_fashion = X_train_fashion / 255.\n",
    "X_test_fashion = X_test_fashion / 255.\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_fashion = Y_train_fashion.flatten()\n",
    "Y_test_fashion = Y_test_fashion.flatten()\n",
    "\n",
    "label_names = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_fashion.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_fashion = X_train_fashion[shuffled_indices]\n",
    "Y_train_fashion = Y_train_fashion[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND9b1ShF745M"
   },
   "source": [
    "``Digits MNIST``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACD38quoz8D_"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train_digits = X_train_digits / 255.\n",
    "X_test_digits = X_test_digits / 255.\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_digits = Y_train_digits.flatten()\n",
    "Y_test_digits = Y_test_digits.flatten()\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_digits.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_digits = X_train_digits[shuffled_indices]\n",
    "Y_train_digits = Y_train_digits[shuffled_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg1uVat9SpDL"
   },
   "source": [
    "---\n",
    "### Step 3: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UfURFDXSpDL"
   },
   "source": [
    "\n",
    "1. Show the first training example in X_train_fashion;\n",
    "2. Show the first training example in X_train_digits;\n",
    "3. Display the first 5 images in X_train_digits for each class in Y_train_digits, arranged in a 10x5 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Md49DRG_SpDM",
    "outputId": "22ab0c88-21f4-4f19-8a8d-bff4213371b9"
   },
   "outputs": [],
   "source": [
    "# First training example in X_train_fashion\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(X_train_fashion[0])\n",
    "plt.title(\"First Training Example in Fashion Dataset\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# First training example in X_train_digits\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(X_train_digits[0])\n",
    "plt.title(\"First Training Example in Digits Dataset\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Function to find first 5 images per class and display them\n",
    "def display_first_5_images_per_class(X_train, Y_train, num_classes=10):\n",
    "    plt.figure(figsize=(15, 30))\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "\n",
    "        class_indices = np.where(Y_train == class_id)[0][:5]\n",
    "\n",
    "        for i, idx in enumerate(class_indices):\n",
    "            plt.subplot(num_classes, 5, class_id * 5 + i + 1)\n",
    "            plt.imshow(X_train[idx])\n",
    "            plt.title(class_id)\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_first_5_images_per_class(X_train_digits, Y_train_digits, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09EpBz1w0_Nj"
   },
   "source": [
    "### Step 4: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GeBGPGhQ5bu"
   },
   "outputs": [],
   "source": [
    "def build_model(n_classes,\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.01,\n",
    "                metric='metric'):\n",
    "    \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "    activation: The activation function to use for the hidden layers.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "    metric: The desired metric.\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28)),  # Define input explicitly\n",
    "    tf.keras.layers.Flatten(),  # No input_shape needed here\n",
    "    ])\n",
    "\n",
    "    for i, hidden_layer_size in enumerate(hidden_layer_sizes):\n",
    "      model.add(tf.keras.layers.Dense(units=hidden_layer_size,\n",
    "                                    activation=activation,\n",
    "                                    name=f'Hidden_{i+1}'))\n",
    "\n",
    "\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(units=n_classes, activation='softmax', name='Output'))\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizers = {\n",
    "      'SGD': tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "      'Adam': tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "      'RMSprop': tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "      'Adagrad': tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    }\n",
    "    optimizer = optimizers.get(optimizer, tf.keras.optimizers.SGD(learning_rate=learning_rate))\n",
    "\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[metric])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NnR0jwkSpDN"
   },
   "source": [
    "---\n",
    "### Step 5: Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "OKeyZXLJJlA4",
    "outputId": "d96fe928-78f3-46fa-a78e-2c9176149d4d"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='tanh',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10):\n",
    "\n",
    "  # Build the model.\n",
    "    model = build_model(n_classes=10,\n",
    "                      hidden_layer_sizes=hidden_layer_sizes,\n",
    "                      activation=activation,\n",
    "                      optimizer=optimizer,\n",
    "                      metric=metric,\n",
    "                      learning_rate=learning_rate)\n",
    "\n",
    "  # Select the dataset.\n",
    "    if data == 'digits':\n",
    "        X_train = X_train_digits\n",
    "        X_test = X_test_digits\n",
    "        Y_train = Y_train_digits\n",
    "        Y_test = Y_test_digits\n",
    "\n",
    "    elif data == 'fashion':\n",
    "        X_train = X_train_fashion\n",
    "        X_test = X_test_fashion\n",
    "        Y_train = Y_train_fashion\n",
    "        Y_test = Y_test_fashion\n",
    "    else:\n",
    "        raise 'Unsupported dataset: %s' %data\n",
    "\n",
    "  # Train the model.\n",
    "    print('Training the', data, 'model...')\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=64,\n",
    "        validation_split=0.1,\n",
    "        verbose=0)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final validation\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('Training accuracy: %1.4f' %train_accuracy[-1])\n",
    "    print('Validation accuracy: %1.4f' %val_accuracy[-1])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# run the function\n",
    "model = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCmcHewtSpDO"
   },
   "source": [
    "1. Conduct experiments and record the training and validation set accuracy results in the table below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ddqOToQ6WW"
   },
   "source": [
    "Data | Hidden sizes | Activation| Optimizer | Learning rate | #Parameters | Training accuracy| Validation accuracy\n",
    "-|-|-|-|-|-|-|-\n",
    " digits | [] | tanh | Adam |0.01| 7850 | 0.9245 | 0.9098\n",
    " digits | [] | tanh | SGD |0.01| 7850 | 0.9002 | 0.9025\n",
    " digits | [] | relu | SGD |0.01| 7850 | 0.9011 | 0.8998\n",
    " digits | [] | relu | Adam |0.01| 7850 | 0.9247 | 0.9093\n",
    " digits | [128] | relu | Adam |0.01| 101770 | 0.9819 | 0.9622\n",
    " digits | [256, 128] | relu | Adam |0.01| 235146 | 0.9798 | 0.9640\n",
    "-|-|-|-|-|-|-|-\n",
    " fashion | [] | tanh | SGD |0.01| 7850 | 0.8354 | 0.8208\n",
    " fashion | [] | relu | SGD |0.01| 7850 | 0.8356 | 0.8205\n",
    " fashion | [] | relu | Adam |0.01| 7850 | 0.8505| 0.8257\n",
    " fashion | [128] | relu | Adam |0.01| 101770 | 0.8834 | 0.8557\n",
    " fashion | [256, 128] | relu | Adam |0.01| 235146 | 0.8820 | 0.8630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "0kVP0rXASpDO",
    "outputId": "96583cd9-c6c4-4cc1-c820-11e832d78096"
   },
   "outputs": [],
   "source": [
    "model1 = train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='tanh',\n",
    "                       optimizer='SGD',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "C4zLzsLCNIPY",
    "outputId": "d2f288b2-d475-446f-f780-58072d4b7509"
   },
   "outputs": [],
   "source": [
    "model2 = train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='relu',\n",
    "                       optimizer='SGD',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "4Wx7VKCcNZwu",
    "outputId": "0c9731ad-2fe5-4f14-977b-1a02ebb54f0b"
   },
   "outputs": [],
   "source": [
    "model3 = train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "GAUnMwZNOJNQ",
    "outputId": "9b0b99cb-f528-4ea8-884f-ab7b05b81408"
   },
   "outputs": [],
   "source": [
    "model4 = train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[128],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "FLDgfCFzRDT-",
    "outputId": "bc994a34-b8a6-4ea7-efde-9a29989f7556"
   },
   "outputs": [],
   "source": [
    "model5 = train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[256,128],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "zUVgmYMjR0A_",
    "outputId": "da37733b-4a23-407d-d673-2713ee281cb4"
   },
   "outputs": [],
   "source": [
    "model6 = train_and_evaluate(data='fashion',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='tanh',\n",
    "                       optimizer='SGD',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "0hFgVFZ3R-HX",
    "outputId": "1b159407-8ab9-435a-ff34-f3e28bb0fcd4"
   },
   "outputs": [],
   "source": [
    "model7 = train_and_evaluate(data='fashion',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='relu',\n",
    "                       optimizer='SGD',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "pXH-zu0GSEKo",
    "outputId": "251532c1-2a6b-4db3-d2a1-2dddb133f95b"
   },
   "outputs": [],
   "source": [
    "model8 = train_and_evaluate(data='fashion',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "RmxDpG8QSIxT",
    "outputId": "2c65f82b-3611-453c-b9fe-ea469e37977c"
   },
   "outputs": [],
   "source": [
    "model9 = train_and_evaluate(data='fashion',\n",
    "                       hidden_layer_sizes=[128],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "ys_k02yfSOZ6",
    "outputId": "643e0b39-7d03-4fdc-98fb-c7819129c8f2"
   },
   "outputs": [],
   "source": [
    "# Preferred architecture configuration\n",
    "# Hidden Layers: [256, 128]\n",
    "# Activation Function: relu\n",
    "# Optimizer: Adam\n",
    "# Learning Rate: 0.01\n",
    "# Number of Epochs: 20\n",
    "\n",
    "model10 = train_and_evaluate(data='fashion',\n",
    "                       hidden_layer_sizes=[256,128],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKa4ZiqFUHbw"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o12N7YXhSpDO"
   },
   "source": [
    "---\n",
    "### Step 6: Evaluation and Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25mwvoGsSpDP",
    "outputId": "b8ab6982-46e3-475d-8b40-5c8c5e325c0b"
   },
   "outputs": [],
   "source": [
    "train_loss_digits, train_accuracy_digits = model5.evaluate(X_train_digits, Y_train_digits)\n",
    "test_loss_digits, test_accuracy_digits = model5.evaluate(X_test_digits, Y_test_digits)\n",
    "\n",
    "print(f\"Aggregate training accuracy for digits datasets: {train_accuracy_digits:.4f}\")\n",
    "print(f\"Aggregate test accuracy for digits datasets: {test_accuracy_digits:.4f}\")\n",
    "\n",
    "\n",
    "train_loss_fashion, train_accuracy_fashion = model10.evaluate(X_train_fashion, Y_train_fashion)\n",
    "test_loss_fashion, test_accuracy_fashion = model10.evaluate(X_test_fashion, Y_test_fashion)\n",
    "\n",
    "print(f\"Aggregate training accuracy for fashion datasets: {train_accuracy_fashion:.4f}\")\n",
    "print(f\"Aggregate test accuracy for fashion datasets: {test_accuracy_fashion:.4f}\")\n",
    "\n",
    "# The model shows strong generalization capabilities because\n",
    "# train and test accuracies are close (gaps: 1% from digits, 2.5% from fashion).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
